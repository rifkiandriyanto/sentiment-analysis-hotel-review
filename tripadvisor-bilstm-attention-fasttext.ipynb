{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8531859,"sourceType":"datasetVersion","datasetId":5095690},{"sourceId":12944,"sourceType":"datasetVersion","datasetId":9235}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch import nn, optim\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom gensim.models import KeyedVectors\nimport re\nimport nltk\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport math\n\n# Load dataset\ndata_path = '/kaggle/input/tripadvisor-1000-dataset-examples/trip-advisor-copy.csv'\ndata = pd.read_csv(data_path)\n\n# Preprocessing: Text Cleaning, Tokenization, and Normalization\nnltk.download('punkt')\n\ndef clean_text(text):\n    text = re.sub(r'[^a-zA-Z\\s]', '', text, re.I | re.A)\n    text = re.sub(r'\\s+', ' ', text).strip()\n    return text.lower()\n\ndata['Cleaned_Review'] = data['Review'].apply(clean_text)\n\n# Adjust labels for sentiment analysis\ndata['Sentiment'] = pd.cut(data['Rating'], bins=[-np.inf, 2, 3, np.inf], labels=['negative', 'neutral', 'positive'], right=False)\n\n# Split data into train and test sets (70% train, 30% test)\ntrain_texts, test_texts, train_labels, test_labels = train_test_split(\n    data['Cleaned_Review'], data['Sentiment'], test_size=0.3, random_state=42)\n\n# Load FastText model\nfasttext_model_path = '/kaggle/input/fasttext-wikinews/wiki-news-300d-1M.vec'\nfasttext_vectors = KeyedVectors.load_word2vec_format(fasttext_model_path, binary=False)\n\n# Convert text data to FastText vectors (average of word vectors)\ndef text_to_vector(text):\n    tokens = nltk.word_tokenize(text.lower())\n    vectors = [fasttext_vectors[word] for word in tokens if word in fasttext_vectors]\n    return np.mean(vectors, axis=0) if vectors else np.zeros(300)\n\ntrain_vectors = np.array([text_to_vector(text) for text in train_texts])\ntest_vectors = np.array([text_to_vector(text) for text in test_texts])\n\n# Define BiLSTM with attention model\nclass Attention(nn.Module):\n    def __init__(self, query_dim, key_dim, value_dim):\n        super(Attention, self).__init__()\n        self.scale = 1. / math.sqrt(query_dim)\n\n    def forward(self, query, keys, values):\n        query = query.unsqueeze(1)  # [BxQ] -> [Bx1xQ]\n        keys = keys.permute(0, 2, 1)  # [BxTxK] -> [BxKxT]\n        energy = torch.bmm(query, keys)  # [Bx1xQ]x[BxKxT] -> [Bx1xT]\n        energy = torch.nn.functional.softmax(energy.mul_(self.scale), dim=2)  # scale, normalize\n\n        values = values.permute(1, 0, 2)  # [TxBxV] -> [BxTxV]\n        linear_combination = torch.bmm(energy, values).squeeze(1)  # [Bx1xT]x[BxTxV] -> [BxV]\n        return energy, linear_combination\n\nclass SentimentBiLSTMWithAttention(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(SentimentBiLSTMWithAttention, self).__init__()\n        self.hidden_size = hidden_size\n        self.bilstm = nn.LSTM(input_size, hidden_size, batch_first=True, bidirectional=True)\n        self.attention = Attention(hidden_size * 2, hidden_size * 2, hidden_size * 2)\n        self.fc = nn.Linear(hidden_size * 2, output_size)  # hidden_size * 2 for bidirectional\n\n    def forward(self, x):\n        bilstm_out, (hn, cn) = self.bilstm(x)\n        bilstm_out = bilstm_out.contiguous()  # Ensure the tensor is contiguous\n        # Pass the entire sequence to the attention mechanism\n        query = hn.transpose(0, 1).contiguous().view(x.size(0), -1)\n        keys = bilstm_out\n        values = bilstm_out\n        energy, linear_combination = self.attention(query, keys, values)\n        output = self.fc(linear_combination)\n        return output\n\n# Define parameters\ninput_size = 300  # Size of FastText word vectors\nhidden_size = 128\noutput_size = len(data['Sentiment'].unique())\n\n# Create BiLSTM with attention model instance\nbilstm_attention_model = SentimentBiLSTMWithAttention(input_size, hidden_size, output_size)\n\n# Define optimizer and loss function\noptimizer = optim.Adam(bilstm_attention_model.parameters(), lr=2e-5)\nloss_fn = nn.CrossEntropyLoss()\n\n# Convert data to tensors\ntrain_vectors_tensor = torch.tensor(train_vectors, dtype=torch.float32)\ntest_vectors_tensor = torch.tensor(test_vectors, dtype=torch.float32)\ntrain_labels_tensor = torch.tensor(train_labels.cat.codes.values, dtype=torch.long)\ntest_labels_tensor = torch.tensor(test_labels.cat.codes.values, dtype=torch.long)\n\n# Define DataLoader\ntrain_dataset = torch.utils.data.TensorDataset(train_vectors_tensor, train_labels_tensor)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)\n\n# Training loop\ndef train_model(model, train_loader, optimizer, loss_fn, num_epochs=10):\n    for epoch in range(num_epochs):\n        model.train()\n        running_loss = 0.0\n        correct_predictions = 0\n\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n\n            outputs = model(inputs)\n            loss = loss_fn(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item() * inputs.size(0)\n            _, predicted = torch.max(outputs, 1)\n            correct_predictions += (predicted == labels).sum().item()\n\n        epoch_loss = running_loss / len(train_loader.dataset)\n        epoch_acc = correct_predictions / len(train_loader.dataset)\n\n        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss}, Accuracy: {epoch_acc}')\n\n# Move model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nbilstm_attention_model = bilstm_attention_model.to(device)\n\n# Train the BiLSTM with attention model\ntrain_model(bilstm_attention_model, train_loader, optimizer, loss_fn, num_epochs=10)\n\n# Evaluate the model\ndef evaluate_model(model, test_vectors_tensor, test_labels_tensor):\n    model.eval()\n    with torch.no_grad():\n        outputs = model(test_vectors_tensor.unsqueeze(0))  # Add extra dimension for batch\n        _, predicted = torch.max(outputs, 1)\n        cm = confusion_matrix(test_labels_tensor.cpu(), predicted.cpu())\n        cr = classification_report(test_labels_tensor.cpu(), predicted.cpu(), target_names=['negative', 'neutral', 'positive'])\n    return cm, cr\n\n# Convert test data to tensor\ntest_vectors_tensor = test_vectors_tensor.to(device)\ntest_labels_tensor = test_labels_tensor.to(device)\n\n# Evaluate the BiLSTM with attention model\nconf_matrix, class_report = evaluate_model(bilstm_attention_model, test_vectors_tensor, test_labels_tensor)\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\nprint(\"\\nClassification Report:\")\nprint(class_report)\n\n# Confusion Matrix Visualization\ndef plot_confusion_matrix(cm, labels):\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n    plt.xlabel('Predicted Label')\n    plt.ylabel('True Label')\n    plt.title('Confusion Matrix')\n    plt.show()\n\nplot_confusion_matrix(conf_matrix, ['negative', 'neutral', 'positive'])\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-30T09:27:32.491025Z","iopub.execute_input":"2024-05-30T09:27:32.491491Z","iopub.status.idle":"2024-05-30T09:30:42.023785Z","shell.execute_reply.started":"2024-05-30T09:27:32.491461Z","shell.execute_reply":"2024-05-30T09:30:42.022239Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[12], line 137\u001b[0m\n\u001b[1;32m    134\u001b[0m bilstm_attention_model \u001b[38;5;241m=\u001b[39m bilstm_attention_model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Train the BiLSTM with attention model\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbilstm_attention_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_model\u001b[39m(model, test_vectors_tensor, test_labels_tensor):\n","Cell \u001b[0;32mIn[12], line 118\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, optimizer, loss_fn, num_epochs)\u001b[0m\n\u001b[1;32m    114\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    116\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 118\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs, labels)\n\u001b[1;32m    120\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[12], line 80\u001b[0m, in \u001b[0;36mSentimentBiLSTMWithAttention.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     78\u001b[0m keys \u001b[38;5;241m=\u001b[39m bilstm_out\n\u001b[1;32m     79\u001b[0m values \u001b[38;5;241m=\u001b[39m bilstm_out\n\u001b[0;32m---> 80\u001b[0m energy, linear_combination \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(linear_combination)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[12], line 57\u001b[0m, in \u001b[0;36mAttention.forward\u001b[0;34m(self, query, keys, values)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, query, keys, values):\n\u001b[1;32m     56\u001b[0m     query \u001b[38;5;241m=\u001b[39m query\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# [BxQ] -> [Bx1xQ]\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     keys \u001b[38;5;241m=\u001b[39m \u001b[43mkeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [BxTxK] -> [BxKxT]\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     energy \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(query, keys)  \u001b[38;5;66;03m# [Bx1xQ]x[BxKxT] -> [Bx1xT]\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     energy \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(energy\u001b[38;5;241m.\u001b[39mmul_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# scale, normalize\u001b[39;00m\n","\u001b[0;31mRuntimeError\u001b[0m: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3"],"ename":"RuntimeError","evalue":"permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3","output_type":"error"}]}]}