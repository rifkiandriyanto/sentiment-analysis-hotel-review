Penelitian saya menggunakan  
LSTM-FastText, LSTM-Word2Vec, dan LSTM-Doc2Vec
 BiLSTM-FastText, BiLSTM-Word2Vec, dan BiLSTM-Doc2Vec
 BiLSTM-Attention-FastText, BiLSTM-Attention-Word2Vec, dan BiLSTM-Attention-Doc2Vec.,
data yang saya gunakan adalah data dari kaggle dengan 20.000 dataset. dibawah ini saya cantumkan output hasil penelitian saya menggunakan lstm. untuk yang laiinya saya akan cantumkan 

fasttext - lstm
Total sentiment in train set:
Sentiment
positive    12084
neutral      1270
negative      989
Name: count, dtype: int64

Total sentiment in test set:
Sentiment
positive    5193
neutral      523
negative     432
Name: count, dtype: int64
Epoch 1/10, Loss: 0.7015695631907158, Accuracy: 0.842501568709475
Epoch 2/10, Loss: 0.5728089696425304, Accuracy: 0.842501568709475
Epoch 3/10, Loss: 0.5448581491654981, Accuracy: 0.842501568709475
Epoch 4/10, Loss: 0.5299993021849898, Accuracy: 0.842501568709475
Epoch 5/10, Loss: 0.5153878458264498, Accuracy: 0.842501568709475
Epoch 6/10, Loss: 0.5035551011423133, Accuracy: 0.842501568709475
Epoch 7/10, Loss: 0.48647238975005747, Accuracy: 0.842501568709475
Epoch 8/10, Loss: 0.4653236503810686, Accuracy: 0.842501568709475
Epoch 9/10, Loss: 0.4462626750462725, Accuracy: 0.842501568709475
Epoch 10/10, Loss: 0.42569103517235135, Accuracy: 0.8425712891305863
Confusion Matrix:
[[   0   10  422]
 [   0    3  520]
 [   0    2 5191]]

Classification Report:
              precision    recall  f1-score   support

    negative       0.00      0.00      0.00       432
     neutral       0.20      0.01      0.01       523
    positive       0.85      1.00      0.92      5193

    accuracy                           0.84      6148
   macro avg       0.35      0.34      0.31      6148
weighted avg       0.73      0.84      0.78      6148



word2vec - lstm
Total sentiment in train set:
Sentiment
positive    12084
neutral      1270
negative      989
Name: count, dtype: int64

Total sentiment in test set:
Sentiment
positive    5193
neutral      523
negative     432
Name: count, dtype: int64
Time to build vocab: 0.01 mins
Time to train the model: 1.42 mins
Epoch 1/10, Loss: 0.7316009907312558, Accuracy: 0.7566757303214111
Epoch 2/10, Loss: 0.4080218948501262, Accuracy: 0.8436868158683678
Epoch 3/10, Loss: 0.3512476488229978, Accuracy: 0.858537265565084
Epoch 4/10, Loss: 0.31819322978971076, Accuracy: 0.872551070208464
Epoch 5/10, Loss: 0.29982752765700993, Accuracy: 0.8787561876873736
Epoch 6/10, Loss: 0.2885093629409028, Accuracy: 0.8829394129540542
Epoch 7/10, Loss: 0.28055164519364195, Accuracy: 0.8842641009551697
Epoch 8/10, Loss: 0.274497017723307, Accuracy: 0.8857979502196194
Epoch 9/10, Loss: 0.26966627856571973, Accuracy: 0.888586767064073
Epoch 10/10, Loss: 0.2656815332279855, Accuracy: 0.8897720142229659
Confusion Matrix:
[[ 272   75   85]
 [  88  126  309]
 [  37   51 5105]]

Classification Report:
              precision    recall  f1-score   support

    negative       0.69      0.63      0.66       432
     neutral       0.50      0.24      0.33       523
    positive       0.93      0.98      0.95      5193

    accuracy                           0.90      6148
   macro avg       0.70      0.62      0.65      6148
weighted avg       0.87      0.90      0.88      6148



doc2vec - lstm
Total sentiments in train set:
Sentiment
positive    12084
neutral      1270
negative      989
Name: count, dtype: int64

Total sentiments in test set:
Sentiment
positive    5193
neutral      523
negative     432
Name: count, dtype: int64
Time to build vocab: 0.02 mins
Time to train the model: 2.96 mins
Epoch 1/10, Loss: 0.7383003573526036, Accuracy: 0.7840061353970578
Epoch 2/10, Loss: 0.43762154526888025, Accuracy: 0.8425712891305863
Epoch 3/10, Loss: 0.36712336063601086, Accuracy: 0.8509377396639476
Epoch 4/10, Loss: 0.3198328255896487, Accuracy: 0.8722024681029074
Epoch 5/10, Loss: 0.29259482414107946, Accuracy: 0.883497176322945
Epoch 6/10, Loss: 0.2768288007381591, Accuracy: 0.8893536916962979
Epoch 7/10, Loss: 0.2666254289213483, Accuracy: 0.8938157986474238
Epoch 8/10, Loss: 0.25921726129428113, Accuracy: 0.8980687443352158
Epoch 9/10, Loss: 0.25334678843359804, Accuracy: 0.899532873178554
Epoch 10/10, Loss: 0.24839507767214344, Accuracy: 0.9026005717074531
Confusion Matrix:
[[ 257   82   93]
 [  94  151  278]
 [  42   72 5079]]

Classification Report:
              precision    recall  f1-score   support

    negative       0.65      0.59      0.62       432
     neutral       0.50      0.29      0.36       523
    positive       0.93      0.98      0.95      5193

    accuracy                           0.89      6148
   macro avg       0.69      0.62      0.65      6148
weighted avg       0.88      0.89      0.88      6148


fasttext - bilstm
Total sentiment in train set:
Sentiment
positive    12084
neutral      1270
negative      989
Name: count, dtype: int64

Total sentiment in test set:
Sentiment
positive    5193
neutral      523
negative     432
Name: count, dtype: int64
Epoch 1/10, Loss: 0.6286691148874276, Accuracy: 0.8204001952171791
Epoch 2/10, Loss: 0.5356218821000232, Accuracy: 0.842501568709475
Epoch 3/10, Loss: 0.5310058887700676, Accuracy: 0.842501568709475
Epoch 4/10, Loss: 0.5235082084128757, Accuracy: 0.842501568709475
Epoch 5/10, Loss: 0.5132273243143993, Accuracy: 0.842501568709475
Epoch 6/10, Loss: 0.4991046213201089, Accuracy: 0.842501568709475
Epoch 7/10, Loss: 0.482497809930492, Accuracy: 0.842501568709475
Epoch 8/10, Loss: 0.46482561848149145, Accuracy: 0.842501568709475
Epoch 9/10, Loss: 0.4440034066546971, Accuracy: 0.842501568709475
Epoch 10/10, Loss: 0.42286148264859746, Accuracy: 0.8425712891305863
Confusion Matrix:
[[   0    0  432]
 [   0    0  523]
 [   0    0 5193]]

Classification Report:
              precision    recall  f1-score   support

    negative       0.00      0.00      0.00       432
     neutral       0.00      0.00      0.00       523
    positive       0.84      1.00      0.92      5193

    accuracy                           0.84      6148
   macro avg       0.28      0.33      0.31      6148
weighted avg       0.71      0.84      0.77      6148

word2vec - bilstm
[nltk_data] Downloading package punkt to /usr/share/nltk_data...
[nltk_data]   Package punkt is already up-to-date!

Total sentiment in train set:
Sentiment
positive    12084
neutral      1270
negative      989
Name: count, dtype: int64

Total sentiment in test set:
Sentiment
positive    5193
neutral      523
negative     432
Name: count, dtype: int64
Time to train the model: 1.41 mins
Epoch 1/10, Loss: 0.6314, Accuracy: 0.8348
Epoch 2/10, Loss: 0.3792, Accuracy: 0.8476
Epoch 3/10, Loss: 0.3252, Accuracy: 0.8672
Epoch 4/10, Loss: 0.2995, Accuracy: 0.8799
Epoch 5/10, Loss: 0.2859, Accuracy: 0.8834
Epoch 6/10, Loss: 0.2769, Accuracy: 0.8861
Epoch 7/10, Loss: 0.2702, Accuracy: 0.8878
Epoch 8/10, Loss: 0.2651, Accuracy: 0.8897
Epoch 9/10, Loss: 0.2612, Accuracy: 0.8914
Epoch 10/10, Loss: 0.2578, Accuracy: 0.8937
Confusion Matrix:
[[ 279   82   71]
 [  93  151  279]
 [  31   77 5085]]

Classification Report:
              precision    recall  f1-score   support

    negative       0.69      0.65      0.67       432
     neutral       0.49      0.29      0.36       523
    positive       0.94      0.98      0.96      5193

    accuracy                           0.90      6148
   macro avg       0.71      0.64      0.66      6148
weighted avg       0.88      0.90      0.89      6148

doc2vec - bilstm
[nltk_data] Downloading package punkt to /usr/share/nltk_data...
[nltk_data]   Package punkt is already up-to-date!

Total sentiments in train set:
Sentiment
positive    12084
neutral      1270
negative      989
Name: count, dtype: int64

Total sentiments in test set:
Sentiment
positive    5193
neutral      523
negative     432
Name: count, dtype: int64
Time to build vocab: 0.02 mins
Time to train the model: 2.96 mins
Epoch 1/10, Loss: 0.6743708952255776, Accuracy: 0.8127309488949314
Epoch 2/10, Loss: 0.4159025365888773, Accuracy: 0.8431987729205884
Epoch 3/10, Loss: 0.34064669784197943, Accuracy: 0.8595830718817542
Epoch 4/10, Loss: 0.2972075803027729, Accuracy: 0.883288015059611
Epoch 5/10, Loss: 0.2749921398437844, Accuracy: 0.8940946803318692
Epoch 6/10, Loss: 0.2619692888477068, Accuracy: 0.8989751098096632
Epoch 7/10, Loss: 0.2528564210911528, Accuracy: 0.9030188942341212
Epoch 8/10, Loss: 0.24563811078230807, Accuracy: 0.9063654744474656
Epoch 9/10, Loss: 0.2394599861121148, Accuracy: 0.9085965279230287
Epoch 10/10, Loss: 0.23391490702251647, Accuracy: 0.9104789792930349
Confusion Matrix:
[[ 262   83   87]
 [ 104  149  270]
 [  39   82 5072]]

Classification Report:
              precision    recall  f1-score   support

    negative       0.65      0.61      0.63       432
     neutral       0.47      0.28      0.36       523
    positive       0.93      0.98      0.95      5193

    accuracy                           0.89      6148
   macro avg       0.69      0.62      0.65      6148
weighted avg       0.87      0.89      0.88      6148

